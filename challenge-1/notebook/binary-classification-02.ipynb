{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":102966,"databundleVersionId":12412856,"sourceType":"competition"}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Importing libraries for file handling, data processing, image manipulation, and visualization\nimport os\nimport pandas as pd\nimport numpy as np\nfrom PIL import Image\nimport matplotlib.pyplot as plt\n\n# PyTorch imports for building neural networks and data loading\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision.transforms as transforms\n\n# Progress bar for loops (e.g., training epochs)\nfrom tqdm import tqdm\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T08:50:51.950456Z","iopub.execute_input":"2025-05-25T08:50:51.950990Z","iopub.status.idle":"2025-05-25T08:50:51.954936Z","shell.execute_reply.started":"2025-05-25T08:50:51.950967Z","shell.execute_reply":"2025-05-25T08:50:51.954305Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define dataset paths and hyperparameters for model training\n\nDATA_DIR = '/kaggle/input/soil-classification-part-2/soil_competition-2025/'  # Base directory for dataset\n\n# Paths to CSV files containing labels and IDs for train and test sets\nTRAIN_CSV = os.path.join(DATA_DIR, 'train_labels.csv')\nTRAIN_IMG_DIR = os.path.join(DATA_DIR, 'train')\nTEST_CSV = os.path.join(DATA_DIR, 'test_ids.csv')\nTEST_IMG_DIR = os.path.join(DATA_DIR, 'test')\n\n# Image size to resize all input images (128x128 pixels)\nIMG_SIZE = 128\n\n# Training parameters\nBATCH_SIZE = 64     # Number of samples per batch during training\nEPOCHS = 20         # Number of full passes through the training dataset\nLR = 1e-3           # Learning rate for optimizer\n\n# Select device: GPU if available, otherwise CPU\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T09:11:30.301383Z","iopub.execute_input":"2025-05-25T09:11:30.302107Z","iopub.status.idle":"2025-05-25T09:11:30.306665Z","shell.execute_reply.started":"2025-05-25T09:11:30.302071Z","shell.execute_reply":"2025-05-25T09:11:30.306033Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Custom PyTorch Dataset class to load soil images for training/testing\n\nclass SoilImageDataset(Dataset):\n    def __init__(self, dataframe, img_dir, transform=None):\n        \"\"\"\n        Args:\n            dataframe (pd.DataFrame): DataFrame containing image metadata (e.g., image IDs).\n            img_dir (str): Directory where images are stored.\n            transform (callable, optional): Optional image transformations (augmentation, normalization).\n        \"\"\"\n        self.df = dataframe.reset_index(drop=True)  # Reset index to ensure sequential indexing\n        self.img_dir = img_dir\n        self.transform = transform\n\n    def __len__(self):\n        # Return total number of samples in the dataset\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        # Fetch image ID for given index\n        img_id = self.df.loc[idx, 'image_id']\n\n        # Construct full image path and load the image\n        img_path = os.path.join(self.img_dir, img_id)\n        image = Image.open(img_path).convert('RGB')  # Ensure image is in RGB format\n\n        # Apply transformations if any are specified\n        if self.transform:\n            image = self.transform(image)\n\n        # Return processed image tensor\n        return image\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T08:51:30.682423Z","iopub.execute_input":"2025-05-25T08:51:30.682677Z","iopub.status.idle":"2025-05-25T08:51:30.687984Z","shell.execute_reply.started":"2025-05-25T08:51:30.682658Z","shell.execute_reply":"2025-05-25T08:51:30.687335Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define basic image transformations: resize images and convert them to PyTorch tensors\ntransforms_basic = transforms.Compose([\n    transforms.Resize((IMG_SIZE, IMG_SIZE)),  # Resize all images to fixed size (128x128)\n    transforms.ToTensor(),                     # Convert PIL Image to PyTorch tensor (C x H x W), values scaled [0,1]\n])\n\n# Load training data CSV with labels\ntrain_df = pd.read_csv(TRAIN_CSV)\n\n# Initialize custom dataset for training images with defined transformations\ntrain_dataset = SoilImageDataset(train_df, TRAIN_IMG_DIR, transform=transforms_basic)\n\n# Create DataLoader to batch training data and shuffle it for randomness\ntrain_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n\n# Load test data CSV (which only contains image IDs, no labels)\ntest_df = pd.read_csv(TEST_CSV)\n\n# Initialize dataset and DataLoader for test images (batch size 1, no shuffling)\ntest_dataset = SoilImageDataset(test_df, TEST_IMG_DIR, transform=transforms_basic)\ntest_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T08:51:48.927485Z","iopub.execute_input":"2025-05-25T08:51:48.928072Z","iopub.status.idle":"2025-05-25T08:51:48.937374Z","shell.execute_reply.started":"2025-05-25T08:51:48.928049Z","shell.execute_reply":"2025-05-25T08:51:48.936776Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define a simple convolutional Autoencoder architecture using PyTorch\n\nclass Autoencoder(nn.Module):\n    def __init__(self):\n        super(Autoencoder, self).__init__()\n        \n        # Encoder: progressively downsamples the input image and extracts features\n        self.encoder = nn.Sequential(\n            nn.Conv2d(3, 16, 3, stride=2, padding=1),  # Input channels=3 (RGB), output=16 feature maps\n                                                      # Output size: [16, 64, 64] (128/2=64)\n            nn.ReLU(),                                 # Activation function\n            \n            nn.Conv2d(16, 32, 3, stride=2, padding=1), # Output: [32, 32, 32]\n            nn.ReLU(),\n            \n            nn.Conv2d(32, 64, 3, stride=2, padding=1), # Output: [64, 16, 16]\n            nn.ReLU()\n        )\n        \n        # Decoder: upsamples the encoded features back to original image size\n        self.decoder = nn.Sequential(\n            nn.ConvTranspose2d(64, 32, 3, stride=2, padding=1, output_padding=1), # Upsample to [32, 32, 32]\n            nn.ReLU(),\n            \n            nn.ConvTranspose2d(32, 16, 3, stride=2, padding=1, output_padding=1), # Upsample to [16, 64, 64]\n            nn.ReLU(),\n            \n            nn.ConvTranspose2d(16, 3, 3, stride=2, padding=1, output_padding=1),  # Upsample to [3, 128, 128]\n            nn.Sigmoid()  # Output values scaled between 0 and 1 for image reconstruction\n        )\n\n    def forward(self, x):\n        # Forward pass: encode input then decode to reconstruct image\n        x = self.encoder(x)\n        x = self.decoder(x)\n        return x\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T08:52:08.920248Z","iopub.execute_input":"2025-05-25T08:52:08.920520Z","iopub.status.idle":"2025-05-25T08:52:08.926161Z","shell.execute_reply.started":"2025-05-25T08:52:08.920500Z","shell.execute_reply":"2025-05-25T08:52:08.925538Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Initialize the Autoencoder model and move it to the selected device (GPU or CPU)\nmodel = Autoencoder().to(device)\n\n# Define the loss function as Mean Squared Error (MSE), suitable for reconstruction tasks\ncriterion = nn.MSELoss()\n\n# Use Adam optimizer for training, with the specified learning rate\noptimizer = torch.optim.Adam(model.parameters(), lr=LR)\n\n# Training loop over defined number of epochs\nfor epoch in range(EPOCHS):\n    model.train()  # Set model to training mode\n    epoch_loss = 0  # Initialize variable to accumulate loss over the epoch\n\n    # Iterate over batches of images from the training DataLoader\n    for images in train_loader:\n        images = images.to(device)            # Move batch to GPU/CPU\n        outputs = model(images)                # Forward pass: get reconstructed images\n        loss = criterion(outputs, images)     # Calculate reconstruction loss\n\n        optimizer.zero_grad()   # Clear previous gradients\n        loss.backward()         # Backpropagate to compute gradients\n        optimizer.step()        # Update model weights\n\n        epoch_loss += loss.item() * images.size(0)  # Accumulate total loss weighted by batch size\n\n    # Print average loss per image for the epoch\n    print(f\"Epoch {epoch+1}/{EPOCHS}, Loss: {epoch_loss / len(train_loader.dataset):.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T08:52:26.349414Z","iopub.execute_input":"2025-05-25T08:52:26.349674Z","iopub.status.idle":"2025-05-25T08:55:27.061760Z","shell.execute_reply.started":"2025-05-25T08:52:26.349655Z","shell.execute_reply":"2025-05-25T08:55:27.061069Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Set model to evaluation mode (disables dropout, batchnorm updates, etc.)\nmodel.eval()\n\nreconstruction_errors = []  # List to store reconstruction errors for each test image\n\n# Disable gradient calculation for faster inference and lower memory usage\nwith torch.no_grad():\n    # Iterate through test dataset using a progress bar\n    for image in tqdm(test_loader):\n        image = image.to(device)           # Move image to GPU/CPU\n        output = model(image)              # Get reconstructed image from the autoencoder\n        loss = criterion(output, image)   # Compute reconstruction error (MSE)\n        reconstruction_errors.append(loss.item())  # Save the loss value for this image\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T08:55:35.288654Z","iopub.execute_input":"2025-05-25T08:55:35.289253Z","iopub.status.idle":"2025-05-25T08:55:42.158435Z","shell.execute_reply.started":"2025-05-25T08:55:35.289227Z","shell.execute_reply":"2025-05-25T08:55:42.157732Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Determine anomaly detection threshold based on reconstruction errors\n# Images with error below threshold are labeled '1' (normal), others '0' (anomaly)\n\nthreshold = np.mean(reconstruction_errors) + 2 * np.std(reconstruction_errors)  \n# Threshold set as mean plus two standard deviations (a common heuristic)\n\n# Generate predictions: 1 if reconstruction error is less than threshold, else 0\npredictions = [1 if err < threshold else 0 for err in reconstruction_errors]\n\n# Prepare submission file by copying test dataframe and adding predicted labels\nsubmission_df = test_df.copy()\nsubmission_df['label'] = predictions\n\n# Save predictions to CSV file for submission\nsubmission_df.to_csv('submission.csv', index=False)\n\n# Display first few rows of the submission file\nprint(submission_df.head())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T08:55:48.190602Z","iopub.execute_input":"2025-05-25T08:55:48.190873Z","iopub.status.idle":"2025-05-25T08:55:48.208496Z","shell.execute_reply.started":"2025-05-25T08:55:48.190853Z","shell.execute_reply":"2025-05-25T08:55:48.207856Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Prepare submission DataFrame with correct column name and order\n\nsubmission_df = test_df.copy()          # Copy original test dataframe\nsubmission_df['# label'] = predictions  # Add predictions under the column named '# label'\n\n# Reorder columns to have 'image_id' first, then '# label'\nsubmission_df = submission_df[['image_id', '# label']]\n\n# Save submission file without the index column\nsubmission_df.to_csv('submission.csv', index=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T08:57:21.631351Z","iopub.execute_input":"2025-05-25T08:57:21.631830Z","iopub.status.idle":"2025-05-25T08:57:21.640140Z","shell.execute_reply.started":"2025-05-25T08:57:21.631805Z","shell.execute_reply":"2025-05-25T08:57:21.639509Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Save submission\nsubmission_df.to_csv('/kaggle/working/submission.csv', index=False)\n\n# Save model\ntorch.save(model.state_dict(), '/kaggle/working/best_model.pth')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T08:58:52.087281Z","iopub.execute_input":"2025-05-25T08:58:52.087943Z","iopub.status.idle":"2025-05-25T08:58:52.096299Z","shell.execute_reply.started":"2025-05-25T08:58:52.087924Z","shell.execute_reply":"2025-05-25T08:58:52.095695Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\n\nprint(\"Files in working directory:\")\nprint(os.listdir('/kaggle/working'))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T09:00:19.898446Z","iopub.execute_input":"2025-05-25T09:00:19.899022Z","iopub.status.idle":"2025-05-25T09:00:19.903159Z","shell.execute_reply.started":"2025-05-25T09:00:19.898976Z","shell.execute_reply":"2025-05-25T09:00:19.902442Z"}},"outputs":[],"execution_count":null}]}
